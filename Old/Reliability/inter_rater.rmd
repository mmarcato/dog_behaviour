---
title: "Ethogram Inter-rater realiability - preliminary analysis"
author: "Marinara Marcato"
output:
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/marinara.marcato/Project/Scripts/dog_ethogram")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# install.packages("irr")
library(DescTools)
# plot
# library(ggplot2)
# library(ggpubr)
# data analysis
library(irr) # reliability (icc, cohen's kappa)
# datasets
library(dplyr)
library(plyr)
library(tidyverse)
```

# Introduction 
This document shows the data analysis carried out to investigate the inter-rater reliability of the ethogram filled out by two dog trainers.


# Data Exploration
Hallgreen2012 was used to define the methodology for the inter-rater reliability analysis.
Two raters analysed a subset of the subject dogs (N=13).
Two different data types were present in the scoring system: ordinal and categorical.

```{r, echo = FALSE}
# import data
vars <- read.csv("0_data/0_raw/ethogram-variables-trainers.csv", stringsAsFactors=FALSE)
print(table(vars$Type))
vars %>% filter(Type == "score") 
ord <- vars %>% filter(Type == "ordinal") %>% pull("Variable")
cat <- vars %>% filter(Type == "categorical") %>% pull("Variable")

# icc(ratings, model, type, unit)
inter <- read.csv("0_data/2_prepare/2022-07-22_Ethogram-Trainers_Inter-Rater.csv", header = TRUE)
# number of scorings per assessor per data collection
inter %>% group_by(Assessor, Data.Collection.Number) %>% count()
```
- Ordinal data
Intraclass correlation coefficient (ICC) was used using IRR package (icc).
Parameters: model = Two-way model as same raters across subjects, 
unit = single rating as a subset of subjects are rated by multiple raters, 
type = absolut agreement.

McGarrity2016 -> performs inter-rater reliability, they had 6 assessors and 54 dogs (I'm not sure if all 6 assessors assessed all 54 subject dogs). 

- Categorical data: 
Cohen Kappa was used using IRR package (kappa2). This model was chosen because there was only 2 assessors. 

## Ordinal
```{r, echo = FALSE}
inter_icc <- function(x,y){
  # cat("x", x)
  data <- y %>% select(Assessor, Name, Data.Collection.Number, x) %>% 
              spread(key = Assessor, value = x) %>% 
              select(-c(Data.Collection.Number, Name)) %>% na.omit()
  result <- icc(data, model = "twoway", unit = "single", type = "consistency")
  # print(result)
  return(c(
        result$value, result$lbound, result$ubound, # estimate value and CI
        result$Fvalue, result$p.value, # F-test results # degrees of freedom are related to sujects result$df1, result$df2, 
        result$raters, result$subjects # dataset raters and subjects
  ))
}

inter_icc <- as.data.frame(t(sapply(ord, inter_icc, y = inter, simplify = TRUE)))
colnames(inter_icc) <- c("ICC", "Low CI", "Upper CI",
            "Fvalue", "Pvalue", "Raters", "Subjects")
            
# total of 24 out of 53 variables had ICC<0.6 or Pvalue >0.05
# total of 14 out of 53 variables had ICC<0.4 or Pvalue >0.05
# total of 10 out of 53 variables had ICC<0.4 or Pvalue >0.05
icc_poor <- inter_icc %>% 
    filter(ICC < 0.4 & Pvalue > 0.05) %>% 
    select(ICC, Pvalue) 
icc_poor
```

```{r, echo = FALSE}
# visualise poor results
icc_print <- function(x,y){
    print(x)
    print(y %>% 
        select(Assessor, Name, Data.Collection.Number, x) %>%
        spread(key = Assessor, value = x))
}
sapply(rownames(icc_poor), icc_print, y = inter)
```
<!-- 
Varibles used in model 

dc1 
Lying.Settled 
S.Walking.Distractions.Pull_prod ->  ** [Walking.Pull.strength, Walking.Pull.on.leash]
S.Sensitivity_mean -> Body.check.Table, Body.check.Response
S.Kong.Response_prod -> Kong.Interaction.Response.to.stimulus 
S.Crate.Stimulus_mean -> Crate.Behaviours..Sniffing.Exploring.., Crate.Behaviours..Digging., Crate.Behaviours..Nudging.Crate.
S.Crate.Handler_prod
S.Sociability_mean
Tea.Towel.First.Response..Indifferent.

dc2
Distractions.First.Response..Car. 
S.Walking.Distractions.Pull_mean  ->  ** [Walking.Pull.strength, Walking.Pull.on.leash]
S.Isolation.Handler_mean  
S.Kong.Response_prod -> Kong.Interaction.Response.to.stimulus 
Crate.Behaviours..Sniffing.Exploring.. -> **
S.Familiarisation.Handler_mean -> Familiarisation.Response..Oriented.to.Handler.
S.Sensitivity_mean -> Body.check.Table, Body.check.Response
S.Walking.Pull_mean -> [Walking.Pull.strength, Walking.Pull.on.leash]
S.Isolation.Stimulus -> Isolation.Response..Unsettled.Pacing.
Distractions.Second.Response..Car.
S.Crate.Handler_mean

-->


## Categorical
```{r, echo = FALSE}
inter_cat <- function(x,y){
  cat("x", x)
  data <- y %>% select(Assessor, Name, Data.Collection.Number, x) %>% 
              spread(key = Assessor, value = x) %>% 
              select(-c(Data.Collection.Number, Name)) %>% na.omit()
  result <- kappa2(data)
  print(result)
  return(c(
        result$value, result$statistic, result$p.value, 
        result$raters, result$subjects # dataset raters and subjects
  ))
}
inter_kappa <- as.data.frame(t(sapply(cat, inter_cat, y = inter, simplify = TRUE)))
colnames(inter_kappa) <- c("Kappa", "Z", "Pvalue", "Raters", "Subjects")

# total of 8 out of 17 variables had ICC<0.6 or Pvalue >0.05
kappa_poor <- inter_kappa %>% 
      filter(Kappa < 0.2 | Pvalue > 0.05) %>% 
      select(Kappa, Pvalue) %>% nrow()
kappa_poor
```


```{r, echo = FALSE}
# visualise poor results
kappa_print <- function(x,y){
    print(x)
    print(y %>% 
        select(Assessor, Name, Data.Collection.Number, x) %>%
        spread(key = Assessor, value = x))
}
sapply(rownames(kappa_poor), kappa_print, y = inter)
```
<!-- 
^Body.check.General..Mouths.  -> No change
Body.check.General..Licks.   -> very divergent, NAs and No mixed?
*Tea.Towel.First.Response..Attempts.to.Removes.towel.by.moving. 
-Tea.Towel.Second.Response..Indifferent. 
-Tea.Towel.Second.Response..Turns.head. 
*Tea.Towel.Second.Response..Attempts.to.Removes.towel.by.moving. 
^Tea.Towel.Second.Response..Plays. -> No change, 1 divergence
^Isolation.Urinating -> No change

- 4 different scores out of 13
* thinking about merging this with mouth
^ there was no or little change (this is called prevalence problem)
-->