---
title: "Ethogram Data Collection 2 - Outcome (Success, Fail)"
author: "Marinara Marcato"
output: 
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/marinara.marcato/Project/Scripts/dog_ethogram")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
# install.packages("lmtest")
library(DescTools)
# plot
library(ggplot2)
library(ggpubr)
library(ggmosaic)
library(cowplot)
# datasets
library(plyr)
library(dplyr)
# library(conflicted) # prevent conflicts between packages
library(tidyverse)
library(reshape2) # remove?

library(ggsci)  # colors for the graphs - png colours for nature
library(broom)  # convert r output into tibbles
library(xtable) # latex table output
# machine learning/stats
library(recipes)
library(caret)
library(rstatix)
library(mlbench) # remove?
library(PRROC)  # calculates precision recall curve
library(lmtest) # lr test (log likelihood ratio test, nested models)
```

```{r output, include = FALSE, results = "hide", message = FALSE}
# save dataframes to csv and print LaTeX table
tab_results <- function(df, name, caption=NULL) {

    # remove the dots from the rownames
    rownames(df) <- gsub("[.]", " ", rownames(df))
    
    path = paste("3_analysis/dc2-new/", name, ".csv", sep = "")

    # save csv file
    write.csv(df, path)
    cat("dataframe saved to ", path)
    
    # latex code for table
    # print(xtable(df,
    #     caption = paste(caption, ".", sep = ""),
    #     label = paste("T-dc2-new-", name, sep = "")),
    #     caption.placement = "top")
}

# save images as png and print LaTeX table
fig_results <- function(plot, name, caption = NULL, label = NULL){

    path = paste("3_analysis/dc2-new/", name, ".png", sep = "")
    
    # if label is not given, use name
    if (is.null(label)){
        label = name
    }
    # save png
    suppressMessages(ggsave(filename = path, 
                plot = plot + theme(text = element_text(size = 20)),
                width = 12, height = 8))
#     cat("Image saved at", path)

    # latex code for image
    # cat("\n\nStart LaTeX code\n\n",
    #         paste("\\begin{figure}[!h]\n\\centering\n\\caption{", paste(caption, ".", sep = ""),"}","\n\\label{F-dc2-new-", label, "}\n\\includegraphics[width = 11cm]{",path,"}\n\\end{figure}", sep = ""), 
    #         "\n\nEnd LaTeX Code\n\n")
}
```


# Introduction 
This document shows the data analysis carried out to investigate the association between ethogram scores filled out by two trainers and the dog's training outcome.
Statistical methods will be used to test the hypothesis that there is a relationship between ethogram scores at dc2 and training outcome (Success, Fail). 


# Data Exploration
The dataset comprised of the following types and number of variables. The original ethogram items contained ordinal and categorical variables. 
The score variables were numerical derived from the original ethogram items.

```{r, echo = FALSE}
vars <- read.csv('0_data/0_raw/ethogram-variables-trainers.csv', stringsAsFactors=FALSE)
print(table(vars$Type))
ord <- vars %>% filter(Type == "ordinal") %>% pull("Variable")
cat <- vars %>% filter(Type == "categorical") %>% pull("Variable")

dc2 <- read.csv('0_data/2_prepare/2022-07-22_Ethogram-Trainers-DC2.csv', 
          stringsAsFactors=TRUE,        # imports character columns as factors
          na.strings=c("")              # imports "" as NA
        )

# changing data types          
dc2$Data.Collection.Date <- as.Date(dc2$Data.Collection.Date, format= "%Y-%m-%d")
dc2$DOB = as.Date(dc2$DOB, format= "%Y-%m-%d")
dc2$DOA = as.Date(dc2$DOA, format= "%Y-%m-%d")
dc2$End.Date = as.Date(dc2$End.Date, format= "%Y-%m-%d")
dc2$Duration = as.numeric(gsub(" .*$", "", dc2$Duration))
# dc2 %>% select(Data.Collection.Date, DOB, DOA, End.Date, Duration) %>% str()

dc2$Outcome <- relevel(dc2$Outcome, "Success")
levels(dc2$Outcome)
```
All ordinal (N = 53) and categorical (N = 17) variables from the original ethogram items, 
score (N = 42) variables derived from the original ethogram items and 
demographical variables (N = 2) - namely, Sex and Breed - will be analysed.

## Demographics

Overview of the dogs participating in the data collection. 
Inclusion criteria: only Labrador Retrievers (LR) and Labrador Retrievers crossed with Golden Retrievers (LRxGR) were kept for data analysis.
```{r, echo = FALSE}
# removing dogs based on breed in the dc2 dataset
cat('Original dataset (dogs, variables): ', dim(dc2))
print(table(dc2$Breed))
levels(dc2$Breed)[levels(dc2$Breed) == "LRx"] <- "LRxGR"
dc2 <- dc2 %>% filter(Breed == "LRxGR" | Breed == "LR")
dc2$Breed <- droplevels(dc2$Breed)
print(table(dc2$Breed))
cat('Final dataset (dogs, variables): ', dim(dc2))
print(table(dc2$Outcome))
print(prop.table(table(dc2$Outcome)))

# Sex
print(table(dc2$Sex))
```

Calculate descriptive statistics for age at arrival at the training centre for formal training. 
Calculate descriptive statistics for age at assessment when the dogs performed the behaviour test at data collection 1, which should be around week 3 of formal training.
```{r, echo = FALSE}
# n <- dim(dc2)[1]

dc2$Age.at.Arrival <- dc2$DOA - dc2$DOB
cat('Age at Arrival: Mean', round(mean(dc2$Age.at.Arrival)/30.417, 2), 
            'Standard Deviation', round(sd(dc2$Age.at.Arrival)/30.417, 2), 
            'Minimum:', round(min(dc2$Age.at.Arrival)/30.417, 2),
            'Maximum:', round(max(dc2$Age.at.Arrival)/30.417, 2))         
# mean <- mean(dc2$Age.at.Arrival)
# margin <- qt(0.975,df=n-1)*sd(std)/sqrt(n)
# 'Confidence Interval', round((mean-margin)/30.417, 2), round((mean+margin)/30.417, 2)

dc2$Age.at.Assessment <- dc2$Data.Collection.Date - dc2$DOB
cat('Age at Assessment: Mean', round(mean(dc2$Age.at.Assessment)/30.417, 2), 
            'Standard Deviation', round(sd(dc2$Age.at.Assessment)/30.417, 2), 
            'Minimum:', round(min(dc2$Age.at.Assessment)/30.417, 2),
            'Maximum:', round(max(dc2$Age.at.Assessment)/30.417, 2))
# mean <- mean(dc2$Age.at.Assessment)
# margin <- qt(0.975,df=n-1)*sd(std)/sqrt(n)
# 'Confidence Interval', round((mean-margin)/30.417, 2), round((mean+margin)/30.417, 2)

```

Calculate statistics of duration of training for the dogs that were withdrawn from training. 
Performing this behaviour test at the beginning on the training (Week 3) would allow assistance dog training organisations to understand which dog are more suitable and allow them to make informed decisions when analysing which dogs to keep for training considering the results of this objective assessment. 
```{r, echo = FALSE}
# Duration of training before withdrawal in weeks
duration <- dc2 %>% filter(Outcome == "Fail") %>% select(Duration)/7
print('Duration of Training in weeks')
summary(duration)

# dc2 %>% arrange(Duration) %>% select(Duration, Name)

h <- ggplot(duration, aes(x=Duration)) +
 geom_histogram(binwidth = 1) +
 xlab("Duration (Weeks)") +
 ylab("Number of Dogs") + theme_bw()
 
h

fig_results(h, name = "duration-histogram",
            caption = "Duration of training in weeks for dogs that were withdrawn from training for behavioural reasons.")
# duration <- dc2 %>% filter(Outcome == "Fail") %>% pull(Duration)/7
# print('Duration of Training in weeks')
# summary(duration)

# print("Histogram of Duration of Training")
# h <- hist(duration, breaks = max(dc2$Duration)/7 , plot = FALSE)
# plot(h, ylab = "Number of Dogs Withdrawn", xlab = "Duration (Weeks)", main = NULL)
```

## Descriptive Statistics

```{r, echo = FALSE}
# selecting features for the analysis
dc <- dc2 %>% select(all_of(ord), all_of(cat), matches("^S[.]"), Sex, Breed, Outcome) # Name, Data.Collection.Date

# NUMERICAL
stats <- data.frame(do.call(rbind, lapply(dc %>% select(where(is.numeric)), summary)))
# missing values, there is something weird about the NAs calculations using summary
stats$NA.s <- colSums(is.na(dc %>% select(where(is.numeric))))
# print('Features sorted by number of missing rows')
# print(stats[order(stats$NA.s, decreasing = TRUE), 'NA.s', drop = FALSE])
# stats
# save csv and print latex code
tab_results(stats, name = "descriptive-statistics-numerical")

# CATEGORICAL
stats <- data.frame(do.call(rbind, lapply(dc %>% select(where(is.factor), 
                -Sex, -Breed, -Kong.Interaction.Lateralisation, -Outcome), summary)))
stats$NA.s <- colSums(is.na(dc %>% select(where(is.factor), 
                -Sex, -Breed, -Kong.Interaction.Lateralisation, -Outcome)))
# missing values, there is something weird about the NAs calculations using summary
# print('Features sorted by number of missing rows')
# print(stats[order(stats$NA.s, decreasing = TRUE), 'NA.s', drop = FALSE])
stats
tab_results(stats, name = "descriptive-statistics-ordinal")

tab_results(table(dc$Kong.Interaction.Lateralisation), name = 'kong-lateralisation')
```

## Feature Selection
Metholodogy adapted from Hosmer2013, pg 107 (GLOW study example).

### Step 1: Univariate logistic regression model results. 
Features which achieved P < 0.25 were selected for consideration to be included in the reduced feature set. 
Subsequentely, related variables were removed considering two cases: 
- Two scores: when both the mean and product scores were selected, the score with the highest p-value was removed.
- Score and original items: when both the original item and the score derived from it were selected, the one with the highest p-value was removed.


<!-- 
Positive estimates increase the probability of failure, while negative estimates decrease the probability of failure.  -->

Categorical: 1 out of 17 ethogram items, 1 out of 2 demographics variables (Sex and Breed).
```{r, echo = FALSE}
# CATEGORICAL: univariate logistic regression using one predictor and outcome
dc_cat <- dc %>% select(all_of(cat), -c(Isolation.Urinating, Crate.Urinating, 
                Body.check.General..Mouths.), Sex, Breed, Outcome)
dc_cat_lr <- lapply(dc_cat[-length(dc_cat)], 
                        function(x) summary(glm(formula = Outcome ~ x, 
                        data = dc_cat, 
                        family = binomial(link = logit), na.action = na.exclude)))
# results in list                       
dc_cat_res <- lapply(dc_cat_lr, function(x) c(coef(x), x$deviance))

# 2 factors -> add to dataframe
dc_cat_res <- data.frame(do.call(rbind, dc_cat_res[lapply(dc_cat_res, length) == 9]))

colnames(dc_cat_res)
# 4 factors p>0.2
cat("Categorical variable with 4 factors:", levels(dc$Kong.Interaction.Lateralisation))
print(dc_cat_lr[14])
```

Ordinal: 7 out of 53 ethogram items. Score: 10 out of 42 variables.
```{r, echo = FALSE}
# ORDINAL: univariate logistic regression using one predictor and outcome
dc_ord <- dc %>% select(all_of(ord), matches("^S[.]"), Outcome)
dc_ord_lr <- lapply(dc_ord[-length(dc_ord)],
                      function(x) summary(glm(formula = Outcome ~ x, 
                      data = dc_ord,
                      family = binomial(link = logit), na.action = na.exclude)))

# results in dataframe
dc_ord_res <- lapply(dc_ord_lr, function(x) round(c(coef(x), x$deviance), 4))
dc_ord_res <- data.frame(do.call(rbind,dc_ord_res))
```

Save results from univariate analysis.
```{r, echo = FALSE}
# saving univariate logistic regression results to csv
dc_lr <- rbind(dc_ord_res, dc_cat_res)
colnames(dc_lr) <- c("estimate_0", "estimate_1", "se_0", "se_1", "z_value_0", "z_value_1",
                    "p_value_0", "p_value_1", "deviance")          
tab_results(dc_lr, name = "univariate-logistic regression.csv", )
tab_results(dc_lr %>% filter(p_value_1 < 0.25) %>% select(estimate_1, p_value_1), 
                name = "significant-variables-25.csv")
```

Variables whose logistic regression model resulted in p<0.25 when used to predict Outcome are shown.
**Variables with p < 0.25 (N = 33): original (N = 18), scores (N = 15) some are repeated**, 
**after removing related variables: variables (N = 14): original (N = 7), scores (N = 7)**.
```{r, echo = FALSE}
# features based on univariate analysis the p values: 32 features < 0.25
dc_lr %>% filter(p_value_1 < 0.25) %>% select(p_value_1)
dc_lr %>% filter(p_value_1 > 0.10 & p_value_1 < 0.15) %>% rownames()

data_1 <- dc %>% select(all_of(dc_lr %>% filter(p_value_1 < 0.25) %>% rownames()), Kong.Interaction.Lateralisation, Outcome)
data_1 %>% colnames()

# drop original items and scores pvalue < 0.25, taking into account the pvalue
feat_drop <- c( 
            # duplicated scores
            "S.Walking.Pull_prod",
            "S.Walking.Distractions.Pull_mean", # dropping because of walking.pull_mean 
            "S.Walking.Distractions.Pull_prod", # dropping because of walking.pull_mean
            "S.Familiarisation.Handler_prod",
            "S.Sensitivity_prod",
            "S.Kong.Response_mean",
            "S.Crate.Handler_prod",

            # removing because of "S.Familiarisation.Handler_mean", p-value smaller
            "Familiarisation.Response..Oriented.to.Handler.",
            "Familiarisation.Response..Waiting.",

            # removing because of "S.Walking.Pull_mean"
            "Walking.Pull.on.leash", # p-value smaller, but not significantly 2 decimal places
            "Walking.Pull.strength",
            
            # removing because of 
            "S.Sensitivity_mean",
            # "Body.check.Table", # p-value smaller

            # removing because of 
            "S.Distractions.First.Response_mean",
            # "Distractions.First.Response..Car.", # p-value smaller
            
            # removing because of 
            "S.Kong.Response_prod",
            # "Kong.Interaction.Response.to.stimulus", # p-value smaller
            # "Kong.Interaction.Back",
            # "Kong.Return.Handler", # p-value smaller
            
            # removing because of 
            "S.Crate.Handler_mean",
            # "Crate.Behaviours..Actively.Seeking.Attention.", # p-value smaller
            # "Crate.Behaviours..Whining.",
            
            # removing because of 
            "S.Isolation.Handler_mean",
            # "Isolation.Response..Time.oriented.", # p-value smaller
            
            # removing because of "S.Isolation.Stimulus", # p-value smaller
            "Isolation.Response..Exploration.",

            # 0.20
            "Walking.Initiative",
            "Crate.Behaviours..Whining.",
            "S.Kong.Response_mean",
            "Tea.Towel.Second.Response..Turns.head.",

            # 0.15
            "Distractions.Second.Response..Car.",

            #0.10
            "Kong.Interaction.Back",
            "Crate.Behaviours..Sniffing.Exploring..",
            "Crate.Behaviours..Actively.Seeking.Attention.",
            "S.Isolation.Handler_mean"
            )

# removing associated original ethogram items and scores based on the p values
data_1 <- data_1 %>% select(-all_of(feat_drop))
data_1 %>% colnames()

# keeping only scores
# data_1 <- data_1 %>% select(c(matches("^S[.]")), Outcome)

# visualise pvalues of the variables selected for next step 
dc_lr %>% filter(row.names(dc_lr) %in% colnames(data_1)) %>% select(p_value_1) %>% arrange(desc(p_value_1))
```

### Step 2: Correlation
```{r, echo = FALSE}
# transform data from factor to numeric (factors, Yes=2, No=1)
data_2 <- data_1 %>% mutate_all(function(x) as.numeric(x))
# calculate correlation
correlationMatrix <- round(abs(cor(data_2 %>% select(-Outcome),use = "pairwise.complete.obs")),2)

plot <- ggplot(data = melt(correlationMatrix), aes(x=Var1, y=Var2, fill=value)) + 
        geom_tile() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
        xlab("Variables") + ylab(NULL)
plot

fig_results(plot = plot, name = "correlation", caption = "Correlation matrix for variables considered for the reduced feature set")

# find highly corrected features (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.4, names = TRUE, exact = TRUE)
print(highlyCorrelated)
# results: >0.7 S.Crate.Stimulus_mean, S.Sensitivity_mean, >0.6 Petting.Responsiveness.After

# remove highly correlated features
data_2 <- data_1 %>% select(-all_of(highlyCorrelated))
colnames(data_2)
```

### Step 3: Multivariate model 
The first multivariate model was built using the features selected in the step above. 
Then, the feature with the highest p-value above 20% significant level in the multivariate model was removed from the dataset. 
Another multivariate model was built and the procedure was repeated until no feature had a p-value above 20%.
The difference in deviance was monitored to make sure the variable did not significantly affect model fitness.  

```{r, echo = FALSE}
print("Initial multivariate model")
glm_full <- glm(Outcome ~ ., data=data_2, family = binomial(link = logit))
summary(glm_full)
# model_full <- data.frame(tidy(glm_full), row.names = 1)
# model_full %>% arrange(desc(p.value)) %>% select(p.value)

# iterate process to find the list of variables to remove;
#       remove the variable with the highest p-value; until the highest variable has (p < 0.05), monitoring the deviance

data_3 <- data_2 %>% select(
    # step1 p<0.10 univariate choose based on pvalue; step2 remove highlycorrelated
    -Kong.Interaction.Lateralisation, -Isolation.Response..Time.oriented., -Kong.Return.Handler, -Body.check.Table,
    -Kong.Interaction.Response.to.stimulus)

glm_reduced <- glm(Outcome ~ ., data=data_3, family = binomial(link = logit))
summary(glm_reduced)
# names(glm_full$coefficients)
# names(glm_reduced$coefficients)
# cat("increase in deviance", glm_reduced$deviance - glm_full$deviance)
# lrtest(glm_full, glm_reduced)
# model_reduced <- data.frame(tidy(glm_reduced), row.names = 1)
# model_reduced %>% arrange(desc(p.value)) %>% select(p.value)
# glm_full <- glm_reduced

data_reduced <- data_3
data_3 %>% colnames()
```

## Missing Data
dc2, missing values per column and per row. Very few data are missing considering the original items selected.
```{r, echo = FALSE}
# reduced dataset
dc_col_nas <- unlist(lapply(data_reduced, function (x) sum(is.na(x))))
print(dc_col_nas)
dc_row_nas <- apply(data_reduced, 1, function (x) sum(is.na(x)) ) 
table(dc_row_nas)
```

## Visualization

<!-- I think for the factors, because they are continuous variables (average of discrete variables), it is better to only have the boxplot. -->

```{r, echo = FALSE}
#categorical
cat_feat <- data_reduced %>% select(where(is.factor), -Outcome) %>% colnames()

# geom_mosaic won't work properly with aes_string
cat("Plot these features manually: ", cat_feat)

# var = "Body.check.General..Licks."
# plot1 <- ggplot(data_reduced, aes_string( x = var, fill = 'Outcome', width = 1)) + 
#         geom_bar(position = "dodge") +
#         theme(legend.position = c(0.85,0.88)) 

# plot2 <- ggplot(data = data_reduced) +
#         geom_mosaic(aes(x=product(Body.check.General..Licks., Outcome), fill = Outcome), alpha = 0.5) +
#         theme(legend.position = "none")

# plot3 <- plot_grid(plot1, plot2, rel_widths = c(2, 1), labels = "AUTO")

# title <- ggdraw() + 
#     draw_label(gsub("[.]", " ", var), fontface = 'bold')

# plot <- plot_grid(title, plot3, ncol = 1, rel_heights = c(0.1, 1))
                
# fig_results(plot = plot3,
#                 name = gsub("[.]", "-", var),
#                 caption = gsub("[.]", " ", var),
#                 label = unlist(strsplit(var, "[.]"))[1])
# plot

# var = "Tea.Towel.Second.Response..Turns.head."
# plot1 <- ggplot(data_reduced, aes_string( x = var, fill = 'Outcome', width = 1)) + 
#         geom_bar(position = "dodge") +
#         theme(legend.position = c(0.85,0.88)) 

# plot2 <- ggplot(data = data_reduced) +
#         geom_mosaic(aes(x=product(Tea.Towel.Second.Response..Turns.head., Outcome), fill = Outcome), alpha = 0.5) +
#         theme(legend.position = "none")

# plot3 <- plot_grid(plot1, plot2, rel_widths = c(2, 1), labels = "AUTO")

# title <- ggdraw() + 
#     draw_label(gsub("[.]", " ", var), fontface = 'bold')

# plot <- plot_grid(title, plot3, ncol = 1, rel_heights = c(0.1, 1))

# fig_results(plot = plot3,
#                 name = gsub("[.]", "-", var),
#                 caption = gsub("[.]", " ", var),
#                 label = unlist(strsplit(var, "[.]"))[1])
# plot

# var = "Breed"
# plot1 <- ggplot(data_reduced, aes_string( x = var, fill = 'Outcome', width = 1)) + 
#         geom_bar(position = "dodge") +
#         theme(legend.position = c(0.85,0.88)) 

# plot2 <- ggplot(data = data_reduced) +
#         geom_mosaic(aes(x=product(Breed, Outcome), fill = Outcome), alpha = 0.5) +
#         theme(legend.position = "none")

# plot3 <- plot_grid(plot1, plot2, rel_widths = c(2, 1), labels = "AUTO")

# title <- ggdraw() + 
#     draw_label(gsub("[.]", " ", var), fontface = 'bold')

# plot <- plot_grid(title, plot3, ncol = 1, rel_heights = c(0.1, 1))

# fig_results(plot = plot3,
#                 name = gsub("[.]", "-", var),
#                 caption = gsub("[.]", " ", var),
#                 label = unlist(strsplit(var, "[.]"))[1])
    
# plot

```

```{r, echo = FALSE}
# numerical
num_feat <- data_reduced %>% select(where(is.numeric))  %>% colnames()

# discrete
plot_discrete <- function(var){
    
    plot1 <- ggplot(data_reduced, aes_string( x = var, fill = 'Outcome', width = 1)) + 
            geom_bar(position = "dodge") +
            theme(legend.position = c(0.84,0.88)) 
            # scale_x_discrete("Rating", limits = c(0:4), breaks = c(0:4), labels = c(0:4)) +
            # expand_limits(x = c(0,4))

    plot2 <- ggplot(data_reduced, aes_string( x = 'Outcome', y = var)) + 
            geom_violin(position = "dodge", width = 0.8, aes(color = Outcome, fill = Outcome), alpha = 0.2) +
            theme(legend.position = "none") +
            geom_boxplot(position = "dodge", aes(colour = Outcome), fill = "white",  width = 0.3) +
            ylab("Rating")
    plot3 <- plot_grid(plot1, plot2, rel_widths = c(2, 1), labels = "AUTO")

    title <- ggdraw() + 
      draw_label(gsub("[.]", " ", var), fontface = 'bold')
    
    plot <- plot_grid(title, plot3, ncol = 1, rel_heights = c(0.1, 1))

    fig_results(plot = plot3,
                name = gsub("[.]", "-", var),
                caption = gsub("[.]", " ", var),
                label = unlist(strsplit(var, "[.]"))[1])
    plot
}

disc_feat <- num_feat[!grepl("^S[.]", num_feat)]
lapply(disc_feat, plot_discrete)

# continuous
plot_continuous <- function(var){

    bin = ceiling((max(data_reduced[var], na.rm = TRUE) - min(data_reduced[var], na.rm = TRUE)) / 5)
    # cat(var, bin, "\n") 
    
    plot1 <- ggplot(data_reduced, aes_string(x = var, fill = 'Outcome')) + 
            geom_histogram(binwidth = bin, position = "dodge") +
            theme(legend.position = c(0.84,0.88)) 

    plot2 <- ggplot(data_reduced, aes_string( x = 'Outcome', y = var)) + 
            geom_violin(position = "dodge", width = 0.8, aes(color = Outcome, fill = Outcome), alpha = 0.2) +
            theme(legend.position = "none") +
            geom_boxplot(position = "dodge", aes(colour = Outcome), fill = "white",  width = 0.3) +
            ylab("Rating")
    plot3 <- plot_grid(plot1, plot2, rel_widths = c(2, 1), labels = "AUTO")

    title <- ggdraw() + 
      draw_label(gsub("S[.]|[.]", " ", var), fontface = 'bold')
    
    plot <- plot_grid(title, plot3, ncol = 1, rel_heights = c(0.1, 1))

    fig_results(plot = plot3,
                name = gsub("[.]", "-", var),
                caption = gsub("[.]", " ", var),
                label = unlist(strsplit(var, "[.]"))[1])

    plot
}

cont_feat <- num_feat[grepl("^S[.]", num_feat)]
lapply(cont_feat, plot_continuous)
```

# Multivariate Model

## Preprocessing: Normalization + Imputation + PCA

## Recursive Feature Elimination (RFE) + Multivariate Logistic Regression (LR)
```{r, echo = FALSE}
data_reduced <- data_3
# columns used as predictors
data_reduced %>% colnames()

# GLM predicts the SECOND class -> make sure Fail is second class
# data_reduced$Outcome <- relevel(data_reduced$Outcome, ref = "Success")
# RFE calculates the metrics on the FIRST class -> make sure Fail is first class
data_reduced$Outcome <- relevel(data_reduced$Outcome, ref = "Fail")
cat('predicting second class:', levels(data_reduced$Outcome))

model_recipe <- recipe(Outcome ~ ., data = data_reduced )  %>%
                    step_dummy(all_nominal(), -Outcome) %>% 
                    step_impute_mean(all_numeric()) %>%
                    step_normalize(all_numeric()) %>%
                    step_pca(all_predictors(), threshold = 0.95)

# Setting ROC as the metric for the Logistic Regression function
# lrFuncs$summary <- twoClassSummary 
lrFuncs$summary <- prSummary 
set.seed(42)

ctrl <- rfeControl(functions = lrFuncs,         # Logistic Regression
                method = "cv",                  # Cross Validation
                number = 60,                    # Number of folds
                saveDetails = TRUE,
                returnResamp = "all",
                allowParallel = FALSE,
                rerank = TRUE,
                verbose = FALSE)

# Recursive Feature Elimination with feat_lr
model_rfe <- rfe(model_recipe,                 # predict Outcome using all other variables
                data = data_reduced,           # selecting the features from univariate lr
                sizes = 1:(ncol(data_reduced)-1),# from 1 to the number of features in the dataset
                rfeControl = ctrl,
                metric = "Precision",
                maximize = TRUE)

warnings()
print(model_rfe)
model <- summary(model_rfe$fit)
print(model)
```

Model fitness with deviance analysis. Performance metrics ROC and PR curves. 
```{r, echo = FALSE}
# model fitness
dev = model$null.deviance - model$deviance
deg = model$df.null - model$df.residual
cat('\ndeviance difference: ', dev)
cat('\ndf difference: ', deg)
cat('\nlevel of significance: ', pchisq(dev, deg, lower.tail = FALSE))
cat('\nthe model is a good fit: ', pchisq(dev, deg, lower.tail = FALSE) < 0.05)

# cross validated predictions for performance analysis
df_perf <- model_rfe$pred %>% 
            filter(Variables == model_rfe$optsize) %>% # get results from optimum model  
            select(rowIndex, Fail, pred, obs) %>%
            rename(c("Index" = "rowIndex", "Probability" = "Fail", "Predicted" = "pred", "Outcome" = "obs"))

# calculate performance metrics ROC
confusionMatrix(data = df_perf$Predicted, reference = df_perf$Outcome, positive = "Fail")

roc_curve <- roc.curve(scores.class0 = df_perf$Probability,
             weights.class0 = abs(as.numeric(df_perf$Outcome)-2),
             curve=TRUE)
roc_curve
png('3_analysis/dc2-new/roc-curve.png')
plot(roc_curve, xlab = "1 - Specificity")   
dev.off()

# calculate performance metrics PR
confusionMatrix(data = df_perf$Predicted, reference = df_perf$Outcome, positive = "Fail", mode = "prec_recall")

pr_curve <- pr.curve(scores.class0 = df_perf$Probability,
             weights.class0 = abs(as.numeric(df_perf$Outcome)-2),
             curve=TRUE)
pr_curve
png('3_analysis/dc2-new/pr-curve.png')
plot(pr_curve)
dev.off()
```

Plot the logit functions
```{r, echo = FALSE}
# logit function, calculate y given the probability(x)
y <- function(x){ return(log(1/( 1/x - 1 ))) }
df_perf$Estimate <- y(df_perf$Probability)
df_perf$Status <- dc2$Status
th_fail = 0.7
th_success = 0.3

# releveling for the colours in the plot
df_perf$Outcome <- relevel(df_perf$Outcome, "Fail")
df_perf$Status <- relevel(df_perf$Status, "W")

print("Probability predicted by the LR using PRQ data vs true Outcome")
plot <- ggplot(df_perf, aes(x = Estimate, y = Probability, group = Outcome ))  +
    # bottom - green
    geom_rect(aes(xmin = -Inf, xmax = y(th_success), ymin = 0, ymax = th_success), 
            fill = "#99ff99", alpha = 0.2, color = "white") + 
    # top - orange
    geom_rect(aes(xmin = y(th_fail), xmax = Inf, ymin = th_fail, ymax = 1), 
            fill = "#ffff99", alpha = 0.2, color = "white") +  
    theme(legend.position = c(0.14,0.88), text = element_text(size = 20)) +
    geom_point(aes(shape=Outcome, color=Outcome), size = 5)
plot

fig_results(plot = plot, name = 'logit-outcome', 
            caption = "Probability predicted by the best logistic regression model using \acrshort{cbarq} data vs true Outcome")


print("Probability predicted by the LR using PRQ data vs true Status")
# plot Logit vs Status
plot <- ggplot(df_perf, aes(x = Estimate, y = Probability, color = Status )) +
    # bottom - green
    geom_rect(aes(xmin = -Inf, xmax = y(th_success), ymin = 0, ymax =  th_success), 
            fill = "#99ff99", alpha = 0.2, color = "white") + 
    # top - orange
    geom_rect(aes(xmin = y(th_fail), xmax = Inf, ymin =  th_fail, ymax = 1), 
            fill = "#ffff99", alpha = 0.2, color = "white") +  
    theme(legend.position = c(0.14,0.88), text = element_text(size = 20)) +
    geom_point(aes(shape=Status, color=Status), size = 5)
plot

fig_results(plot = plot, name = 'logit-status', 
            caption = "Probability predicted by the best logistic regression model using \acrshort{cbarq} data vs true Status")

print("Estimate and Probabilities per training outcome status")
df_perf %>% group_by(Status) %>% dplyr::summarize(Mean = mean(Estimate, na.rm=TRUE))
df_perf %>% group_by(Status) %>% dplyr::summarize(Mean = mean(Probability, na.rm=TRUE))

cat("Predicted probability <", th_success, " -> Green flag ")
print("Dogs flagged green are likely to SUCCEED, true outcome count and status proportion:")
table(df_perf %>% filter(Probability < th_success) %>% pull(Outcome))
# prop.table(table(df_perf %>% filter(Probability < th_success) %>% pull(Outcome)))
prop.table(table(df_perf %>% filter(Probability < th_success) %>% pull(Status)))

cat("Predicted probability >", th_fail, "-> Yellow flag")
print("Dogs flagged green are likely to FAIL, true outcome count and status proportion:")
table(df_perf %>% filter(Probability > th_fail) %>% pull(Outcome))
prop.table(table(df_perf %>% filter(Probability > th_fail) %>% pull(Outcome)))
prop.table(table(df_perf %>% filter(Probability > th_fail) %>% pull(Status)))

cat(th_success, " < Predicted probability <", th_fail, "-> no flags")
table(df_perf %>% filter(Probability > th_success & Probability < th_fail) %>% pull(Status))
# prop.table(table(df_perf %>% filter(Probability > th_success & Probability < th_fail) %>% pull(Outcome)))
prop.table(table(df_perf %>% filter(Probability > th_success & Probability < th_fail) %>% pull(Status)))
```

Check the dogs that were false positives or false negatives
```{r, echo = FALSE}
# FALSE POSITIVE dogs predicted to fail, but succeed 
df_perf %>% filter(Predicted == "Fail" & Outcome == "Success") %>% arrange(Probability) %>% select(Index, Probability)
dc2$Name[df_perf %>% filter(Predicted == "Fail" & Outcome == "Success") %>% arrange(Probability) %>% pull(Index)]
# FALSE NEGATIVE dogs predicted to succeed, but failed
df_perf %>% filter(Predicted == "Success" & Outcome == "Fail") %>% arrange(Probability) %>% select(Index, Probability)
dc2$Name[df_perf %>% filter(Predicted == "Success" & Outcome == "Fail") %>% arrange(Probability) %>% pull(Index)]
```

## Interpretation
Discuss model interpretation
```{r, echo = FALSE}
results_rfe <- as.data.frame(coef(summary(model_rfe$fit)))
results_rfe$OR <- exp(results_rfe$Estimate)
results_rfe <- cbind(results_rfe, exp(confint(model_rfe$fit, level = 0.95)))
print("Results from the model created")
print(results_rfe)

# save csv and print latex code
tab_results(results_rfe,
    caption = "Best logistic regression model using selected by RFE",
    name = "rfe-lr")
```

## Feature Importance

### Explained variance
```{r, echo = FALSE}
cat("PCA features kept in the final model after RFE: ", model_rfe$optVariables)
# tidy(recipe steps, number = select pca step, type = coef or variance
dc_pca_var <- as.data.frame(tidy(model_rfe$recipe, number = 4, type = "variance"))
dc_pca_var <- dc_pca_var %>% spread(key = "terms", value = value) %>% select(-c(id))
colnames(dc_pca_var) <- make.names(names(dc_pca_var)) # fixing column names with space

print("Explained Variance per Principal Component (Scree Plot)")
dc_pca_var$Included = factor(c("No", "Yes", "Yes"))
plot <- ggplot(dc_pca_var, aes(x = component, y = percent.variance, fill = Included)) +
    geom_bar(stat='identity', position = 'dodge', width = 0.8)+
    xlab("Principal components") +
    ylab("Explained Variance (%)") 
plot

fig_results(plot = plot, name = 'pc-explained-variance', 
            caption = "Explained variance per principal component (Scree Plot)")

```

### Coefficient loadings
```{r, echo = FALSE}
dc_pca_coef <- as.data.frame(tidy(model_rfe$recipe, number = 4, type = "coef"))
dc_pca_coef <- dc_pca_coef %>% filter(component %in% model_rfe$optVariables) %>% select(-id)
# plot <- ggplot(dc_pca_coef, aes(x=terms, y=value, fill = component)) +
#     geom_bar(stat="identity", position='dodge', width = 0.8) +
#     xlab("Predictor Variables") +
#     ylab("Loadings") +
#     theme(axis.text.x = element_text(angle = 90), legend.position = "top")
# plot

plot <- ggplot(dc_pca_coef %>% filter(component %in% model_rfe$optVariables), 
                    aes(x=component, y=value, fill = terms)) +
    geom_bar(stat="identity", position='dodge', width = 0.8) +
    xlab("Principal Components") +
    ylab("Loadings") +
    theme(axis.text.x = element_text(angle = 90), legend.position = "right") + 
    guides(fill=guide_legend(title = "Predictor variables"))
plot

fig_results(plot = plot, name = 'pc-loading',
            caption = " Principal component (PC3, PC6 and PC8) coefficient loading from original items and factors")

# save csv and print latex code
tab_results(dc_pca_coef %>% remove_rownames %>% spread(key = component, value = value) %>% column_to_rownames(var="terms"), 
            name = 'pc-loading', caption = 'Principal coefficient loading from original items and factors')

# righest loading items for each PC in optimal model
lapply(model_rfe$optVariables, function (x) 
            dc_pca_coef %>% filter(component == x) %>% 
                arrange(desc(abs(value))) %>% 
                select(terms, value))
```

# Conclusion